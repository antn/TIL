{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xy = np.loadtxt('TrainText03.txt', unpack=True, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = np.transpose(xy[0:3])\n",
    "y_data = np.transpose(xy[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\", [None, 3])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "W = tf.Variable(tf.zeros([3, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hypothesis = tf.nn.softmax(tf.matmul(X, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01 # Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis), reduction_indices=1))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.09048 [[-0.00083333  0.00041667  0.00041667]\n",
      " [ 0.00166667  0.00291667 -0.00458333]\n",
      " [ 0.00166667  0.00416667 -0.00583333]]\n",
      "200 0.985653 [[-0.21679303 -0.05050437  0.26729742]\n",
      " [ 0.02901031 -0.06265054  0.03364029]\n",
      " [ 0.04244109  0.12451769 -0.16695869]]\n",
      "400 0.926073 [[-0.41495511 -0.10318027  0.51813519]\n",
      " [ 0.03762176 -0.10302337  0.06540174]\n",
      " [ 0.07457665  0.17761268 -0.25218898]]\n",
      "600 0.879342 [[-0.59596533 -0.1515553   0.74752003]\n",
      " [ 0.04480708 -0.11983915  0.07503238]\n",
      " [ 0.10447746  0.20644082 -0.31091776]]\n",
      "800 0.840971 [[-0.76270223 -0.19499816  0.95770001]\n",
      " [ 0.05223157 -0.12450957  0.07227841]\n",
      " [ 0.13095778  0.22218271 -0.35314   ]]\n",
      "1000 0.808647 [[-0.91752577 -0.2334879   1.15101326]\n",
      " [ 0.06007884 -0.12292791  0.06284945]\n",
      " [ 0.15438823  0.23068959 -0.38507724]]\n",
      "1200 0.780959 [[-1.06231129 -0.26727253  1.32958329]\n",
      " [ 0.06808005 -0.11823834  0.05015875]\n",
      " [ 0.17550454  0.23514733 -0.41065112]]\n",
      "1400 0.756943 [[-1.19854808 -0.29670808  1.49525583]\n",
      " [ 0.07591439 -0.11214777  0.03623381]\n",
      " [ 0.19498996  0.237331   -0.43232018]]\n",
      "1600 0.735892 [[-1.32743537 -0.32218221  1.64961684]\n",
      " [ 0.08333746 -0.10557999  0.022243  ]\n",
      " [ 0.21336642  0.23823628 -0.45160189]]\n",
      "1800 0.717269 [[-1.44994974 -0.34407791  1.79402602]\n",
      " [ 0.09020081 -0.09902246  0.00882213]\n",
      " [ 0.23099625  0.23841871 -0.46941414]]\n",
      "2000 0.700649 [[-1.56689739 -0.36275655  1.92965221]\n",
      " [ 0.09643649 -0.09271803 -0.00371792]\n",
      " [ 0.24811605  0.23818412 -0.48629922]]\n",
      "a : [[ 0.68849677  0.26731515  0.04418808]] [0]\n",
      "b : [[ 0.24322268  0.44183081  0.3149465 ]] [1]\n",
      "c : [[ 0.02974809  0.08208466  0.8881672 ]] [2]\n"
     ]
    }
   ],
   "source": [
    "#______________learning process\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in xrange(2001):\n",
    "        sess.run(optimizer, feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 200 == 0:\n",
    "            print step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W)\n",
    "            \n",
    "#______________Testing parts\n",
    "    \n",
    "    #arg_max() - used for 'one-hot' encoding\n",
    "            \n",
    "    a = sess.run(hypothesis, feed_dict={X: [[1, 11, 7]]})\n",
    "    print \"a :\", a, sess.run(tf.arg_max(a, 1))\n",
    "    \n",
    "    b = sess.run(hypothesis, feed_dict={X: [[1, 3, 4]]})\n",
    "    print \"b :\", b, sess.run(tf.arg_max(b, 1))\n",
    "    \n",
    "    c = sess.run(hypothesis, feed_dict={X: [[1, 1, 0]]})\n",
    "    print \"c :\", c, sess.run(tf.arg_max(c, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
